# Call Analysis System ü§ñ

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![AI Agents](https://img.shields.io/badge/AI%20Agents-5-purple.svg)](#ai-agent-system)
[![NLP](https://img.shields.io/badge/NLP-Advanced-orange.svg)](#advanced-nlp)

> **Revolutionary AI-powered call center analytics platform with autonomous agent processing**

Transform your call center operations with cutting-edge AI agents, advanced NLP analysis, and intelligent automation. This comprehensive system provides autonomous call processing, real-time insights, and predictive analytics for customer service excellence.

## üåü Key Features

### ü§ñ **Autonomous AI Agent System**
- **Multi-Agent Architecture**: Coordinated intelligent agents working together
- **Call Acquisition Agent**: Automatically monitors and acquires calls from multiple sources
- **Analysis Orchestrator**: Coordinates comprehensive NLP analysis workflows  
- **Monitoring Agent**: Real-time system health and performance tracking
- **Workflow Agent**: Manages complex multi-step analysis processes
- **Agent Manager**: Centralized coordination and message routing

### üß† **Advanced NLP & Machine Learning**
- **Intent Classification**: Understand customer purposes (appointments, complaints, emergencies)
- **Entity Extraction**: Identify names, dates, medical terms, insurance providers
- **Topic Modeling**: Discover conversation themes using LDA and advanced techniques
- **Sentiment Analysis**: Multi-dimensional emotional tone detection
- **Linguistic Features**: Advanced text analysis and pattern recognition
- **Custom Models**: Domain-specific models for dental/medical practices

### üìä **Comprehensive Analytics**
- **Real-time Dashboard**: Live metrics and insights
- **Predictive Analytics**: Call volume forecasting and trend analysis
- **Performance Tracking**: Staff and system performance metrics
- **Quality Monitoring**: Automated quality assessment and scoring
- **Custom Reports**: Flexible reporting with multiple export formats
- **Historical Analysis**: Long-term trend identification and insights

### üîÑ **Intelligent Automation**
- **Automated Workflows**: Multi-step processing with conditional logic
- **Error Recovery**: Robust retry mechanisms and error handling
- **Scalable Processing**: Handle high volumes with concurrent processing
- **Real-time Coaching**: Live analysis and coaching suggestions
- **Alert System**: Intelligent notifications and escalation triggers
- **Health Monitoring**: Automated system health checks and maintenance

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Agent Manager                       ‚îÇ
‚îÇ         (Central Coordination Hub)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ Message Routing & Coordination
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Call  ‚îÇ  ‚îÇAnalysis ‚îÇ  ‚îÇMonitoring ‚îÇ  ‚îÇWorkflow ‚îÇ  ‚îÇ Health ‚îÇ
‚îÇAcquis. ‚îÇ  ‚îÇOrchestr.‚îÇ  ‚îÇ  Agent    ‚îÇ  ‚îÇ Agent   ‚îÇ  ‚îÇMonitor ‚îÇ
‚îÇ Agent  ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ            ‚îÇ             ‚îÇ             ‚îÇ           ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ             ‚îÇ             ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ         Advanced NLP Pipeline            ‚îÇ
         ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
         ‚îÇ ‚îÇIntent   ‚îÇ ‚îÇEntity   ‚îÇ ‚îÇTopic    ‚îÇ      ‚îÇ
         ‚îÇ ‚îÇClassify ‚îÇ ‚îÇExtract  ‚îÇ ‚îÇModeling ‚îÇ      ‚îÇ
         ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
         ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
         ‚îÇ ‚îÇSentiment‚îÇ ‚îÇLinguist.‚îÇ ‚îÇCustom   ‚îÇ      ‚îÇ
         ‚îÇ ‚îÇAnalysis ‚îÇ ‚îÇFeatures ‚îÇ ‚îÇModels   ‚îÇ      ‚îÇ
         ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Data Layer    ‚îÇ
                    ‚îÇ PostgreSQL +    ‚îÇ
                    ‚îÇ Redis + Files   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites

- **Python 3.8+** (Python 3.9+ recommended)
- **PostgreSQL 12+** (optional, for data persistence)
- **Redis 6+** (optional, for caching)
- **4GB+ RAM** (8GB+ recommended for production)
- **OpenAI API Key** (optional, for enhanced features)

### Installation

#### 1. Clone and Setup Environment

```bash
# Clone the repository
git clone https://github.com/yourusername/call-analysis.git
cd call-analysis

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Upgrade pip
pip install --upgrade pip
```

#### 2. Install Dependencies

```bash
# Install Python dependencies
pip install -r requirements.txt

# Download required NLP models
python -m spacy download en_core_web_sm

# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet'); nltk.download('averaged_perceptron_tagger')"
```

#### 3. Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit configuration (required)
nano .env
```

**Essential Configuration (.env):**
```env
# Data Directory
DATA_DIR=./data

# Database (optional)
DATABASE_URL=postgresql://user:password@localhost/callanalysis

# Redis Cache (optional)
REDIS_URL=redis://localhost:6379

# OpenAI (optional, for enhanced features)
OPENAI_API_KEY=your_openai_key_here

# Logging
LOG_LEVEL=INFO

# Agent System
MAX_CONCURRENT_CALLS=50
ANALYSIS_TIMEOUT=300
```

#### 4. Initialize System

```bash
# Create data directories
mkdir -p data/{raw,processed,models,logs}

# Initialize database (if using PostgreSQL)
# call-analysis db init

# Test system installation
python test_import.py
```

### Running the System

#### Start the AI Agent System

```bash
# Start the complete agent system
python -m call_analysis.main agents start

# Start with debug logging
python -m call_analysis.main agents start --debug
```

#### Check System Status

```bash
# Overall system health
python -m call_analysis.main agents status

# Detailed view with JSON output
python -m call_analysis.main agents status --format json

# Check specific agent
python -m call_analysis.main agents agent-status analysis_orchestrator
```

#### Run System Tests

```bash
# Run comprehensive system tests
python -m call_analysis.main agents test

# Get system information
python -m call_analysis.main info
```

## üì¶ Project Structure

```
call-analysis/
‚îú‚îÄ‚îÄ src/call_analysis/              # Main application package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                     # CLI entry point
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ models.py                   # Data models
‚îÇ   ‚îú‚îÄ‚îÄ database.py                 # Database connection
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ agents/                     # AI Agent System
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py          # Base agent class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_manager.py       # Agent coordination
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ call_acquisition_agent.py    # Call acquisition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis_orchestrator.py     # Analysis coordination
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitoring_agent.py          # System monitoring
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workflow_agent.py            # Workflow management
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ nlp/                        # Advanced NLP Processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ intent_detection.py    # Intent classification
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_extraction.py   # Named entity recognition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ topic_modeling.py      # Topic discovery
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentiment_analyzer.py  # Sentiment analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linguistic_features.py # Feature extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_preprocessing.py  # Text preprocessing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ advanced_analyzer.py   # Comprehensive NLP
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ cli/                        # Command Line Interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ agent_commands.py      # Agent management commands
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ api.py                      # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py                 # Legacy analyzer
‚îÇ   ‚îú‚îÄ‚îÄ predictor.py               # Predictive models
‚îÇ   ‚îú‚îÄ‚îÄ coaching.py                # Real-time coaching
‚îÇ   ‚îî‚îÄ‚îÄ server.py                  # Server utilities
‚îÇ
‚îú‚îÄ‚îÄ data/                          # Data storage
‚îÇ   ‚îú‚îÄ‚îÄ raw/                       # Raw call data
‚îÇ   ‚îú‚îÄ‚îÄ processed/                 # Processed data
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Trained models
‚îÇ   ‚îî‚îÄ‚îÄ logs/                      # System logs
‚îÇ
‚îú‚îÄ‚îÄ tests/                         # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ unit/                      # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ integration/               # Integration tests
‚îÇ   ‚îî‚îÄ‚îÄ performance/               # Performance tests
‚îÇ
‚îú‚îÄ‚îÄ docs/                          # Documentation
‚îú‚îÄ‚îÄ examples/                      # Usage examples
‚îú‚îÄ‚îÄ scripts/                       # Deployment scripts
‚îú‚îÄ‚îÄ migrations/                    # Database migrations
‚îú‚îÄ‚îÄ requirements.txt               # Python dependencies
‚îú‚îÄ‚îÄ setup.py                       # Package setup
‚îú‚îÄ‚îÄ docker-compose.yml            # Development environment
‚îú‚îÄ‚îÄ Dockerfile                    # Container definition
‚îî‚îÄ‚îÄ README.md                     # This file
```

## ü§ñ AI Agent System

### Agent Architecture

The system uses a multi-agent architecture where specialized agents work together to process calls automatically:

#### Base Agent
```python
class BaseAgent(ABC):
    """Base class for all AI agents"""
    
    async def initialize() -> None        # Agent startup
    async def cleanup() -> None          # Agent shutdown  
    async def process_task(task) -> Dict # Task processing
    async def send_message(...)          # Inter-agent communication
    def get_status() -> Dict            # Health status
```

#### Agent Roles

**üîç Call Acquisition Agent**
- Monitors multiple call sources (files, FTP, APIs, email)
- Automatic call detection and acquisition
- Configurable polling intervals and retry logic
- Supports various file formats (JSON, TXT, audio files)

**üß† Analysis Orchestrator**
- Coordinates comprehensive call analysis
- Manages multiple NLP engines in parallel
- Generates actionable insights
- Handles batch processing for high volume

**üìä Monitoring Agent**
- Real-time system health monitoring
- Resource usage tracking (CPU, memory, disk)
- Alert generation and management
- Performance metrics collection

**‚öôÔ∏è Workflow Agent**
- Complex multi-step workflow execution
- Conditional logic and branching
- Error handling and retry mechanisms
- Predefined and custom workflow templates

**üéõÔ∏è Agent Manager**
- Centralized agent coordination
- Message routing between agents
- Lifecycle management
- Configuration and health monitoring

### Agent Communication

Agents communicate through a sophisticated message routing system:

```python
# Send message between agents
await agent.send_message(
    recipient="analysis_orchestrator",
    subject="analyze_call",
    payload={
        "call_id": "call_001",
        "transcript": "Customer transcript here...",
        "metadata": {"phone": "555-0123"}
    },
    message_type=MessageType.COMMAND,
    priority=3
)
```

### Workflow Examples

**Comprehensive Call Analysis Workflow:**
```yaml
name: "Comprehensive Call Analysis"
steps:
  - name: "Acquire Call"
    agent: "call_acquisition_agent"
    action: "process_call"
    
  - name: "Analyze Content" 
    agent: "analysis_orchestrator"
    action: "analyze_call"
    conditions:
      require: ["step.acquire_call.status == 'success'"]
    
  - name: "Generate Report"
    agent: "workflow_agent" 
    action: "generate_report"
    conditions:
      require: ["step.analyze_content.status == 'success'"]
```

## üß† Advanced NLP & Machine Learning

### Intent Classification

The system can identify customer intents with high accuracy:

```python
from call_analysis.nlp import IntentClassifier

classifier = IntentClassifier()
result = classifier.classify_intent(
    "Hi, I'd like to schedule a dental cleaning appointment for next week"
)

print(result)
# {
#   "primary_intent": "appointment_booking",
#   "confidence": 0.92,
#   "urgency": "medium",
#   "intent_entities": {
#     "preferred_times": ["next week"],
#     "treatments_mentioned": ["cleaning"]
#   }
# }
```

**Supported Intents:**
- `appointment_booking` - Scheduling appointments
- `appointment_cancellation` - Canceling/rescheduling
- `emergency_dental` - Urgent dental issues
- `insurance_inquiry` - Insurance and billing questions
- `treatment_inquiry` - Questions about procedures
- `complaint` - Customer complaints
- `billing_inquiry` - Payment and billing issues
- `follow_up` - Post-treatment follow-up
- `general_inquiry` - General information requests

### Entity Extraction

Advanced named entity recognition for call center contexts:

```python
from call_analysis.nlp import EntityExtractor

extractor = EntityExtractor()
entities = extractor.extract_all(
    "Please call me back at 555-123-4567. My insurance is Blue Cross."
)

print(entities)
# {
#   "phone_numbers": ["555-123-4567"],
#   "insurance_providers": ["Blue Cross"],
#   "medical_terms": [],
#   "persons": [],
#   "dates": [],
#   "all_entities": [...]
# }
```

**Entity Types:**
- **Contact Information**: Phone numbers, email addresses
- **Medical Terms**: Procedures, conditions, symptoms, anatomy
- **Insurance**: Providers, coverage terms
- **Temporal**: Dates, times, scheduling expressions
- **Personal**: Names, locations, organizations

### Topic Modeling

Discover conversation themes using advanced topic modeling:

```python
from call_analysis.nlp import TopicModelingEngine

engine = TopicModelingEngine()
topics = engine.analyze_topics(
    "I'm having severe tooth pain and need an emergency appointment today"
)

print(topics)
# {
#   "dominant_topic": "emergency_dental",
#   "topic_coherence_score": 0.85,
#   "key_themes": ["pain", "emergency", "tooth", "appointment"],
#   "predefined_topic_scores": {
#     "emergency_dental": 0.91,
#     "appointment_booking": 0.67,
#     "treatment_inquiry": 0.23
#   }
# }
```

**Topic Categories:**
- Emergency dental situations
- Appointment scheduling
- Insurance and billing
- Treatment procedures
- Patient concerns and complaints
- Follow-up care

### Sentiment Analysis

Multi-dimensional sentiment analysis with emotion detection:

```python
from call_analysis.nlp import AdvancedSentimentAnalyzer

analyzer = AdvancedSentimentAnalyzer()
sentiment = analyzer.analyze_sentiment(
    "I'm really frustrated with the long wait times at your office"
)

print(sentiment)
# {
#   "compound_score": -0.67,
#   "sentiment_label": "negative",
#   "emotions": {
#     "frustration": 0.89,
#     "disappointment": 0.45,
#     "anger": 0.32
#   },
#   "confidence": 0.91
# }
```

## üñ•Ô∏è Command Line Interface

### Agent Management

```bash
# Start the agent system
call-analysis agents start [--debug]

# Check system status  
call-analysis agents status [--format json|table]

# Check specific agent
call-analysis agents agent-status <agent_id>

# Run system tests
call-analysis agents test
```

### Analysis Operations

```bash
# Analyze single call
call-analysis analyze single "call_001" "transcript text"

# Batch process calls
call-analysis analyze batch --file calls.json

# Export results
call-analysis export --format csv --days 30 --output results.csv
```

### System Operations

```bash
# Database operations
call-analysis db init
call-analysis db health
call-analysis db reset

# Model management
call-analysis models train
call-analysis models info
call-analysis models predict --days 7

# Server operations
call-analysis server start [--reload] [--workers 4]
call-analysis status
```

## üîß Configuration

### Environment Variables

**Core Configuration:**
```env
# System
ENVIRONMENT=development          # development, staging, production
DEBUG=true
LOG_LEVEL=INFO
DATA_DIR=./data

# Database
DATABASE_URL=postgresql://user:pass@host/db
REDIS_URL=redis://localhost:6379

# OpenAI
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4-turbo-preview

# Security
SECURITY_SECRET_KEY=your-secure-secret-key

# Processing
MAX_CONCURRENT_CALLS=50
ANALYSIS_TIMEOUT=300
BATCH_SIZE=100
```

### Agent Configuration

Configure agents via `data/agent_configs.json`:

```json
{
  "call_acquisition_agent": {
    "enabled": true,
    "auto_start": true,
    "max_concurrent_tasks": 10,
    "polling_interval": 300,
    "auto_restart": true
  },
  "analysis_orchestrator": {
    "enabled": true,
    "auto_start": true, 
    "max_concurrent_tasks": 15
  },
  "monitoring_agent": {
    "enabled": true,
    "auto_start": true,
    "max_concurrent_tasks": 5,
    "alert_thresholds": {
      "cpu_usage": 80.0,
      "memory_usage": 85.0,
      "disk_usage": 90.0
    }
  },
  "workflow_agent": {
    "enabled": true,
    "auto_start": true,
    "max_concurrent_tasks": 20
  }
}
```

### Call Source Configuration

Configure call sources in `data/call_sources.json`:

```json
{
  "sources": [
    {
      "source_type": "file_system",
      "name": "Local File Monitor",
      "config": {
        "directory": "./data/incoming_calls",
        "patterns": ["*.txt", "*.json", "*.wav"],
        "recursive": true,
        "move_processed": true
      },
      "enabled": true,
      "polling_interval": 30
    },
    {
      "source_type": "ftp",
      "name": "FTP Server Monitor", 
      "config": {
        "host": "ftp.example.com",
        "username": "user",
        "password": "pass",
        "directory": "/calls",
        "extensions": [".txt", ".wav"]
      },
      "enabled": false,
      "polling_interval": 300
    }
  ]
}
```

## üìä API Reference

### REST API Endpoints

**Call Analysis:**
```http
POST /analyze
Content-Type: application/json

{
  "call_id": "call_001",
  "transcript": "Customer transcript here...",
  "metadata": {
    "phone": "555-0123",
    "timestamp": "2024-01-01T10:00:00Z"
  }
}
```

**Batch Analysis:**
```http
POST /analyze/batch
Content-Type: application/json

[
  {
    "call_id": "call_001", 
    "transcript": "..."
  },
  {
    "call_id": "call_002",
    "transcript": "..."
  }
]
```

**System Health:**
```http
GET /health
GET /agents/status
GET /agents/{agent_id}/status
```

### Python API

**Initialize Agent System:**
```python
from call_analysis.agents import AgentManager

# Initialize system
manager = AgentManager()
await manager.initialize()

# Process call
result = await manager.send_message_to_agent(
    "analysis_orchestrator",
    "analyze_call", 
    {
        "call_id": "call_001",
        "transcript": "Customer transcript...",
        "metadata": {"phone": "555-0123"}
    }
)

# Get system health
health = await manager.get_system_health()
print(f"System status: {health['overall_status']}")

# Shutdown
await manager.shutdown()
```

**Direct NLP Usage:**
```python
from call_analysis.nlp import (
    IntentClassifier, 
    EntityExtractor,
    TopicModelingEngine,
    AdvancedSentimentAnalyzer
)

# Initialize analyzers
intent_classifier = IntentClassifier()
entity_extractor = EntityExtractor() 
topic_engine = TopicModelingEngine()
sentiment_analyzer = AdvancedSentimentAnalyzer()

# Analyze text
text = "I need to schedule an emergency dental appointment"

intent = intent_classifier.classify_intent(text)
entities = entity_extractor.extract_all(text)
topics = topic_engine.analyze_topics(text)
sentiment = sentiment_analyzer.analyze_sentiment(text)

print(f"Intent: {intent['primary_intent']}")
print(f"Entities: {entities['medical_terms']}")
print(f"Topic: {topics['dominant_topic']}")
print(f"Sentiment: {sentiment['sentiment_label']}")
```

## üîç Monitoring & Debugging

### System Health Monitoring

The monitoring agent provides comprehensive system health tracking:

```bash
# Real-time system status
call-analysis agents status

# Detailed health report
call-analysis agents status --format json | jq '.system_info'

# Monitor specific metrics
call-analysis agents agent-status monitoring_agent
```

**Health Indicators:**
- üü¢ **Healthy**: All systems operational
- üü° **Degraded**: Minor issues detected
- üî¥ **Critical**: Immediate attention required

### Performance Metrics

**System Metrics:**
- CPU usage and load average
- Memory utilization
- Disk space and I/O
- Network connectivity
- Queue depths and processing rates

**Agent Metrics:**
- Task completion rates
- Error rates and patterns
- Response times
- Message throughput
- Resource utilization per agent

### Logging and Debugging

**Log Levels:**
```bash
# Debug logging
export LOG_LEVEL=DEBUG
call-analysis agents start

# Structured logging
tail -f data/logs/call_analysis.log | jq '.'
```

**Debug Commands:**
```bash
# Test specific components
python -c "from call_analysis.nlp import IntentClassifier; print('‚úÖ NLP OK')"

# Validate configuration
call-analysis config validate

# Check dependencies
call-analysis deps check
```

### Troubleshooting

**Common Issues:**

1. **Agent Won't Start**
   ```bash
   # Check dependencies
   pip install -r requirements.txt
   
   # Verify NLP models
   python -m spacy download en_core_web_sm
   
   # Check configuration
   call-analysis config validate
   ```

2. **High Memory Usage**
   ```bash
   # Monitor memory
   call-analysis agents status
   
   # Reduce batch sizes
   export BATCH_SIZE=50
   export MAX_CONCURRENT_CALLS=25
   ```

3. **Slow Processing**
   ```bash
   # Check CPU usage
   htop
   
   # Optimize NLP models
   export ENABLE_GPU=true  # If CUDA available
   
   # Increase concurrency
   export MAX_CONCURRENT_TASKS=20
   ```

4. **Database Connection Issues**
   ```bash
   # Test connection
   call-analysis db health
   
   # Reset connection
   call-analysis db reconnect
   ```

## üß™ Testing

### Running Tests

```bash
# Install test dependencies
pip install -e ".[dev]"

# Run all tests
pytest

# Run with coverage
pytest --cov=src/call_analysis --cov-report=html

# Run specific test categories
pytest tests/unit/          # Unit tests
pytest tests/integration/   # Integration tests  
pytest tests/performance/   # Performance tests

# Test specific components
pytest tests/test_agents.py -v
pytest tests/test_nlp.py -v
```

### Test Categories

**Unit Tests:**
- Individual component functionality
- NLP model accuracy
- Agent behavior validation
- Configuration parsing

**Integration Tests:**
- End-to-end workflows
- Agent communication
- Database operations
- API endpoints

**Performance Tests:**
- Processing throughput
- Memory usage patterns
- Concurrent processing
- Load testing

### Benchmarking

```bash
# Run performance benchmarks
pytest tests/performance/ -v

# Specific benchmarks
python tests/performance/benchmark_nlp.py
python tests/performance/benchmark_agents.py

# Load testing
python tests/performance/load_test.py --calls 1000 --concurrent 10
```

## üöÄ Deployment

### Development Environment

```bash
# Quick start
git clone <repo-url>
cd call-analysis
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm

# Start development system
call-analysis agents start --debug
```

### Docker Deployment

```bash
# Build image
docker build -t call-analysis .

# Run with Docker Compose
docker-compose up -d

# Production deployment
docker-compose -f docker-compose.prod.yml up -d
```

**Docker Compose Configuration:**
```yaml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/callanalysis
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./data:/app/data
      
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: callanalysis
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
      
  redis:
    image: redis:7-alpine
    
volumes:
  postgres_data:
```

### Production Deployment

**System Requirements:**
- 4+ CPU cores
- 8GB+ RAM
- 50GB+ storage
- Ubuntu 20.04+ or CentOS 8+

**Deployment Steps:**
```bash
# 1. System preparation
sudo apt update && sudo apt upgrade -y
sudo apt install python3.9 python3.9-venv postgresql redis-server nginx

# 2. Application setup
git clone <repo-url> /opt/call-analysis
cd /opt/call-analysis
python3.9 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm

# 3. Configuration
cp .env.example .env
# Edit .env with production settings

# 4. Database setup
sudo -u postgres createdb callanalysis
call-analysis db init

# 5. System service
sudo cp scripts/call-analysis.service /etc/systemd/system/
sudo systemctl enable call-analysis
sudo systemctl start call-analysis

# 6. Nginx configuration
sudo cp config/nginx.conf /etc/nginx/sites-available/call-analysis
sudo ln -s /etc/nginx/sites-available/call-analysis /etc/nginx/sites-enabled/
sudo systemctl reload nginx
```

### Cloud Deployment

**AWS Deployment:**
```bash
# Using AWS ECS
aws ecs create-cluster --cluster-name call-analysis
aws ecs register-task-definition --cli-input-json file://aws/task-definition.json
aws ecs create-service --cluster call-analysis --service-name call-analysis-service

# Using AWS Lambda (for lightweight processing)
serverless deploy --stage production
```

**Google Cloud:**
```bash
# Using Cloud Run
gcloud run deploy call-analysis --image gcr.io/project/call-analysis --platform managed
```

**Azure:**
```bash
# Using Container Instances
az container create --resource-group rg --name call-analysis --image call-analysis
```

## üîí Security

### Security Best Practices

**API Security:**
```python
# JWT authentication
from fastapi import Security, HTTPException
from fastapi.security import HTTPBearer

security = HTTPBearer()

@app.get("/protected")
async def protected_endpoint(token: str = Security(security)):
    # Validate JWT token
    pass
```

**Data Protection:**
```python
# Encrypt sensitive data
from cryptography.fernet import Fernet

key = Fernet.generate_key()
cipher = Fernet(key)

# Encrypt call transcripts
encrypted_transcript = cipher.encrypt(transcript.encode())
```

**Environment Security:**
```bash
# Secure environment variables
export OPENAI_API_KEY="$(vault kv get -field=api_key secret/openai)"
export DB_PASSWORD="$(vault kv get -field=password secret/database)"

# File permissions
chmod 600 .env
chmod 700 data/
```

### Security Checklist

- [ ] **API Keys**: Stored securely, rotated regularly
- [ ] **Database**: Encrypted at rest, secured connections
- [ ] **Network**: HTTPS only, firewall configured
- [ ] **Authentication**: Strong passwords, MFA enabled
- [ ] **Logging**: Security events logged, monitored
- [ ] **Updates**: Dependencies updated, security patches applied
- [ ] **Backups**: Encrypted, tested, stored securely
- [ ] **Access Control**: Principle of least privilege

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Fork and clone
git clone https://github.com/yourusername/call-analysis.git
cd call-analysis

# Create development environment
python -m venv venv
source venv/bin/activate
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest
```

### Code Standards

**Style Guide:**
- Follow PEP 8 style guidelines
- Use type hints for all functions
- Write comprehensive docstrings
- Maintain test coverage >80%

**Development Workflow:**
1. Create feature branch
2. Write tests first (TDD)
3. Implement functionality
4. Update documentation
5. Submit pull request

**Code Review Checklist:**
- [ ] Tests added/updated
- [ ] Documentation updated
- [ ] Type hints included
- [ ] Error handling implemented
- [ ] Performance considered
- [ ] Security implications reviewed

## üéØ Roadmap

### Current Version: 1.0.0 ‚úÖ

**Core Features Completed:**
- [x] Multi-agent architecture
- [x] Advanced NLP processing
- [x] Real-time monitoring
- [x] Workflow orchestration
- [x] Comprehensive CLI
- [x] Docker deployment
- [x] Extensive documentation

### Version 1.1.0 (Q2 2024)

**Enhanced Intelligence:**
- [ ] Multi-language support (Spanish, French)
- [ ] Custom model training interface
- [ ] Advanced conversation flow analysis
- [ ] Predictive coaching recommendations
- [ ] Integration with popular CRM systems

### Version 1.2.0 (Q3 2024)

**Enterprise Features:**
- [ ] Multi-tenant architecture
- [ ] Advanced RBAC and SSO
- [ ] Real-time dashboard web interface
- [ ] Mobile applications (iOS/Android)
- [ ] Advanced reporting and BI integration
- [ ] Phone system integrations (Asterisk, FreePBX)

### Version 2.0.0 (Q4 2024)

**AI Evolution:**
- [ ] GPT-4 integration for advanced analysis
- [ ] Voice emotion recognition
- [ ] Real-time conversation coaching
- [ ] Automated quality scoring
- [ ] Predictive customer behavior modeling
- [ ] Advanced workflow automation

## üôè Acknowledgments

### Technology Stack

- **[OpenAI](https://openai.com)** - Advanced language models for semantic analysis
- **[spaCy](https://spacy.io)** - Industrial-strength NLP processing
- **[FastAPI](https://fastapi.tiangolo.com)** - Modern, fast web framework
- **[PostgreSQL](https://postgresql.org)** - Robust relational database
- **[Redis](https://redis.io)** - In-memory data structure store
- **[Docker](https://docker.com)** - Containerization platform
- **[Scikit-learn](https://scikit-learn.org)** - Machine learning library
- **[NLTK](https://nltk.org)** - Natural language toolkit
- **[Gensim](https://radimrehurek.com/gensim/)** - Topic modeling
- **[Rich](https://rich.readthedocs.io)** - Beautiful CLI interfaces

### Inspiration

This project was inspired by the need for intelligent, automated call center analytics that can provide real-time insights and improve customer service quality across industries.

---

**üöÄ Ready to transform your call center operations?**

Get started today with the most advanced AI-powered call analysis platform. From autonomous processing to real-time insights, everything you need for call center excellence.

```bash
git clone https://github.com/yourusername/call-analysis.git
cd call-analysis
pip install -r requirements.txt
python -m call_analysis.main agents start
```

